{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "model defined\n",
      "model defined\n",
      "model defined\n",
      "model defined\n",
      "model defined\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.5320 - acc: 0.8407 - val_loss: 0.2825 - val_acc: 0.9166\n",
      "Test loss: 0.267584555462\n",
      "Test accuracy: 0.9206\n",
      "train loss: 0.282466981082\n",
      "train accuracy: 0.9166\n",
      "~\n",
      "[0.91659999999999997]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.2421 - acc: 0.9289 - val_loss: 0.2161 - val_acc: 0.9373\n",
      "Test loss: 0.207694908977\n",
      "Test accuracy: 0.9394\n",
      "train loss: 0.216115570019\n",
      "train accuracy: 0.937316666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s - loss: 0.2018 - acc: 0.9417 - val_loss: 0.1784 - val_acc: 0.9485\n",
      "Test loss: 0.174341753318\n",
      "Test accuracy: 0.9494\n",
      "train loss: 0.178428108653\n",
      "train accuracy: 0.948466666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 20s - loss: 0.1687 - acc: 0.9512 - val_loss: 0.1485 - val_acc: 0.9568\n",
      "Test loss: 0.145838852116\n",
      "Test accuracy: 0.9576\n",
      "train loss: 0.14853298609\n",
      "train accuracy: 0.9568\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.1427 - acc: 0.9586 - val_loss: 0.1258 - val_acc: 0.9640\n",
      "Test loss: 0.122061403034\n",
      "Test accuracy: 0.9646\n",
      "train loss: 0.125759935512\n",
      "train accuracy: 0.964016666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1232 - acc: 0.9645 - val_loss: 0.1140 - val_acc: 0.9666\n",
      "Test loss: 0.113220697703\n",
      "Test accuracy: 0.9666\n",
      "train loss: 0.113990244489\n",
      "train accuracy: 0.9666\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.1078 - acc: 0.9689 - val_loss: 0.0961 - val_acc: 0.9730\n",
      "Test loss: 0.0958068372205\n",
      "Test accuracy: 0.9708\n",
      "train loss: 0.0960814186111\n",
      "train accuracy: 0.972983333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0962 - acc: 0.9719 - val_loss: 0.0851 - val_acc: 0.9758\n",
      "Test loss: 0.0878928614853\n",
      "Test accuracy: 0.9725\n",
      "train loss: 0.0850726872897\n",
      "train accuracy: 0.975833333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0867 - acc: 0.9744 - val_loss: 0.0842 - val_acc: 0.9751\n",
      "Test loss: 0.0866111665744\n",
      "Test accuracy: 0.9734\n",
      "train loss: 0.0842292008738\n",
      "train accuracy: 0.975133333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0795 - acc: 0.9772 - val_loss: 0.0701 - val_acc: 0.9792\n",
      "Test loss: 0.0717510292819\n",
      "Test accuracy: 0.977\n",
      "train loss: 0.0700940521505\n",
      "train accuracy: 0.97925\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0735 - acc: 0.9783 - val_loss: 0.0676 - val_acc: 0.9797\n",
      "Test loss: 0.0697044829681\n",
      "Test accuracy: 0.9775\n",
      "train loss: 0.0675991989993\n",
      "train accuracy: 0.979716666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0669 - acc: 0.9796 - val_loss: 0.0602 - val_acc: 0.9822\n",
      "Test loss: 0.0643995958614\n",
      "Test accuracy: 0.9802\n",
      "train loss: 0.0601759597503\n",
      "train accuracy: 0.982183333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0628 - acc: 0.9810 - val_loss: 0.0574 - val_acc: 0.9832\n",
      "Test loss: 0.0637922957734\n",
      "Test accuracy: 0.9798\n",
      "train loss: 0.0574054101839\n",
      "train accuracy: 0.98325\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0587 - acc: 0.9828 - val_loss: 0.0531 - val_acc: 0.9844\n",
      "Test loss: 0.0603259750761\n",
      "Test accuracy: 0.9812\n",
      "train loss: 0.053128842649\n",
      "train accuracy: 0.9844\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0560 - acc: 0.9835 - val_loss: 0.0523 - val_acc: 0.9842\n",
      "Test loss: 0.0624680771526\n",
      "Test accuracy: 0.9804\n",
      "train loss: 0.052349222423\n",
      "train accuracy: 0.984166666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0531 - acc: 0.9845 - val_loss: 0.0493 - val_acc: 0.9854\n",
      "Test loss: 0.0590272034688\n",
      "Test accuracy: 0.9812\n",
      "train loss: 0.0492872411774\n",
      "train accuracy: 0.985366666667\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0503 - acc: 0.9853 - val_loss: 0.0455 - val_acc: 0.9868\n",
      "Test loss: 0.0562036146116\n",
      "Test accuracy: 0.9818\n",
      "train loss: 0.0454860296431\n",
      "train accuracy: 0.9868\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661, 0.98680000000000001]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 24s - loss: 0.0482 - acc: 0.9859 - val_loss: 0.0442 - val_acc: 0.9876\n",
      "Test loss: 0.0552498961953\n",
      "Test accuracy: 0.9821\n",
      "train loss: 0.0442172025871\n",
      "train accuracy: 0.9876\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661, 0.98680000000000001, 0.98760000000000003]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0463 - acc: 0.9862 - val_loss: 0.0412 - val_acc: 0.9880\n",
      "Test loss: 0.0552648780636\n",
      "Test accuracy: 0.9828\n",
      "train loss: 0.0412451989528\n",
      "train accuracy: 0.987983333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661, 0.98680000000000001, 0.98760000000000003, 0.98798333333333332]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.0444 - acc: 0.9869 - val_loss: 0.0397 - val_acc: 0.9885\n",
      "Test loss: 0.0539896014439\n",
      "Test accuracy: 0.9826\n",
      "train loss: 0.0397282037256\n",
      "train accuracy: 0.988483333333\n",
      "~\n",
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661, 0.98680000000000001, 0.98760000000000003, 0.98798333333333332, 0.98848333333333338]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.5061 - acc: 0.8468 - val_loss: 0.2497 - val_acc: 0.9255\n",
      "Test loss: 0.247649234834\n",
      "Test accuracy: 0.9286\n",
      "train loss: 0.249712672412\n",
      "train accuracy: 0.925466666667\n",
      "~\n",
      "[0.92546666666666666]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.5028 - acc: 0.8474 - val_loss: 0.2127 - val_acc: 0.9374\n",
      "Test loss: 0.204879083645\n",
      "Test accuracy: 0.9401\n",
      "train loss: 0.212690464287\n",
      "train accuracy: 0.937416666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.4859 - acc: 0.8517 - val_loss: 0.2296 - val_acc: 0.9331\n",
      "Test loss: 0.221055042455\n",
      "Test accuracy: 0.9373\n",
      "train loss: 0.229586251974\n",
      "train accuracy: 0.933116666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 24s - loss: 0.5079 - acc: 0.8459 - val_loss: 0.2102 - val_acc: 0.9389\n",
      "Test loss: 0.196929463221\n",
      "Test accuracy: 0.9429\n",
      "train loss: 0.210172032642\n",
      "train accuracy: 0.9389\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff30a92f9e8>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2b0447320>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1798 - acc: 0.9477 - val_loss: 0.1501 - val_acc: 0.9566\n",
      "Test loss: 0.141167655249\n",
      "Test accuracy: 0.959\n",
      "train loss: 0.150053532498\n",
      "train accuracy: 0.956583333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1774 - acc: 0.9482 - val_loss: 0.1486 - val_acc: 0.9563\n",
      "Test loss: 0.141921311929\n",
      "Test accuracy: 0.9574\n",
      "train loss: 0.148601676959\n",
      "train accuracy: 0.9563\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1769 - acc: 0.9489 - val_loss: 0.1491 - val_acc: 0.9576\n",
      "Test loss: 0.146471848889\n",
      "Test accuracy: 0.954\n",
      "train loss: 0.149088077977\n",
      "train accuracy: 0.957633333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1745 - acc: 0.9497 - val_loss: 0.1460 - val_acc: 0.9578\n",
      "Test loss: 0.138179634909\n",
      "Test accuracy: 0.9567\n",
      "train loss: 0.146026844697\n",
      "train accuracy: 0.957833333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2b0447320>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a4cf3940>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1302 - acc: 0.9626 - val_loss: 0.1157 - val_acc: 0.9664\n",
      "Test loss: 0.112422608903\n",
      "Test accuracy: 0.9632\n",
      "train loss: 0.115706671698\n",
      "train accuracy: 0.966433333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1336 - acc: 0.9612 - val_loss: 0.1121 - val_acc: 0.9679\n",
      "Test loss: 0.110761187908\n",
      "Test accuracy: 0.9653\n",
      "train loss: 0.112062447932\n",
      "train accuracy: 0.967916666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1347 - acc: 0.9610 - val_loss: 0.1168 - val_acc: 0.9662\n",
      "Test loss: 0.113009383565\n",
      "Test accuracy: 0.9652\n",
      "train loss: 0.116834884654\n",
      "train accuracy: 0.966183333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1292 - acc: 0.9629 - val_loss: 0.1158 - val_acc: 0.9669\n",
      "Test loss: 0.115001226562\n",
      "Test accuracy: 0.9638\n",
      "train loss: 0.115754285844\n",
      "train accuracy: 0.966883333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2b0447320>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a3948588>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1084 - acc: 0.9691 - val_loss: 0.0987 - val_acc: 0.9709\n",
      "Test loss: 0.097757793708\n",
      "Test accuracy: 0.9696\n",
      "train loss: 0.0986812106151\n",
      "train accuracy: 0.970866666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1060 - acc: 0.9692 - val_loss: 0.0961 - val_acc: 0.9721\n",
      "Test loss: 0.0967362286195\n",
      "Test accuracy: 0.9695\n",
      "train loss: 0.0960514993247\n",
      "train accuracy: 0.9721\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1080 - acc: 0.9687 - val_loss: 0.1018 - val_acc: 0.9710\n",
      "Test loss: 0.100367459013\n",
      "Test accuracy: 0.9685\n",
      "train loss: 0.101816817377\n",
      "train accuracy: 0.971016666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.1067 - acc: 0.9694 - val_loss: 0.0920 - val_acc: 0.9738\n",
      "Test loss: 0.0919460237689\n",
      "Test accuracy: 0.9705\n",
      "train loss: 0.0919646887274\n",
      "train accuracy: 0.973766666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a3948588>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff306e8da90>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0915 - acc: 0.9729 - val_loss: 0.0818 - val_acc: 0.9761\n",
      "Test loss: 0.0825159347557\n",
      "Test accuracy: 0.9743\n",
      "train loss: 0.0817714189038\n",
      "train accuracy: 0.976133333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0914 - acc: 0.9728 - val_loss: 0.0821 - val_acc: 0.9763\n",
      "Test loss: 0.0821974908629\n",
      "Test accuracy: 0.9732\n",
      "train loss: 0.0820503077115\n",
      "train accuracy: 0.9763\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0915 - acc: 0.9733 - val_loss: 0.0827 - val_acc: 0.9751\n",
      "Test loss: 0.080984796711\n",
      "Test accuracy: 0.9749\n",
      "train loss: 0.0826856676392\n",
      "train accuracy: 0.975066666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0917 - acc: 0.9733 - val_loss: 0.0881 - val_acc: 0.9741\n",
      "Test loss: 0.0874498779628\n",
      "Test accuracy: 0.973\n",
      "train loss: 0.0880796480545\n",
      "train accuracy: 0.9741\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff305b5f668>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0815 - acc: 0.9761 - val_loss: 0.0731 - val_acc: 0.9784\n",
      "Test loss: 0.073806768119\n",
      "Test accuracy: 0.9748\n",
      "train loss: 0.0731364011327\n",
      "train accuracy: 0.978416666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0821 - acc: 0.9761 - val_loss: 0.0740 - val_acc: 0.9785\n",
      "Test loss: 0.0769567208766\n",
      "Test accuracy: 0.9732\n",
      "train loss: 0.0739687027126\n",
      "train accuracy: 0.978516666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0819 - acc: 0.9760 - val_loss: 0.0744 - val_acc: 0.9785\n",
      "Test loss: 0.0780786594223\n",
      "Test accuracy: 0.9748\n",
      "train loss: 0.0744393961359\n",
      "train accuracy: 0.9785\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0823 - acc: 0.9758 - val_loss: 0.0748 - val_acc: 0.9783\n",
      "Test loss: 0.0761762100078\n",
      "Test accuracy: 0.9757\n",
      "train loss: 0.0747634078846\n",
      "train accuracy: 0.978283333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff305b5f668>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0747 - acc: 0.9774 - val_loss: 0.0689 - val_acc: 0.9795\n",
      "Test loss: 0.0724557983383\n",
      "Test accuracy: 0.9759\n",
      "train loss: 0.0689423197786\n",
      "train accuracy: 0.9795\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0740 - acc: 0.9781 - val_loss: 0.0697 - val_acc: 0.9795\n",
      "Test loss: 0.0716715655206\n",
      "Test accuracy: 0.9772\n",
      "train loss: 0.0696933784179\n",
      "train accuracy: 0.979466666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0744 - acc: 0.9777 - val_loss: 0.0699 - val_acc: 0.9791\n",
      "Test loss: 0.0748974231672\n",
      "Test accuracy: 0.9758\n",
      "train loss: 0.0698721697828\n",
      "train accuracy: 0.979133333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0744 - acc: 0.9780 - val_loss: 0.0683 - val_acc: 0.9793\n",
      "Test loss: 0.0700281654971\n",
      "Test accuracy: 0.9773\n",
      "train loss: 0.0683309922886\n",
      "train accuracy: 0.979316666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0694 - acc: 0.9792 - val_loss: 0.0628 - val_acc: 0.9814\n",
      "Test loss: 0.0683653806997\n",
      "Test accuracy: 0.9792\n",
      "train loss: 0.0627630693919\n",
      "train accuracy: 0.9814\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0693 - acc: 0.9791 - val_loss: 0.0649 - val_acc: 0.9804\n",
      "Test loss: 0.0686780767669\n",
      "Test accuracy: 0.9782\n",
      "train loss: 0.064865407583\n",
      "train accuracy: 0.980416666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0693 - acc: 0.9789 - val_loss: 0.0649 - val_acc: 0.9804\n",
      "Test loss: 0.0704944128742\n",
      "Test accuracy: 0.9765\n",
      "train loss: 0.064865036755\n",
      "train accuracy: 0.980416666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0690 - acc: 0.9794 - val_loss: 0.0615 - val_acc: 0.9822\n",
      "Test loss: 0.0664067161162\n",
      "Test accuracy: 0.978\n",
      "train loss: 0.0614687814328\n",
      "train accuracy: 0.982166666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff3031942e8>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff3031942e8>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0645 - acc: 0.9807 - val_loss: 0.0633 - val_acc: 0.9805\n",
      "Test loss: 0.0690666469582\n",
      "Test accuracy: 0.977\n",
      "train loss: 0.0632993049598\n",
      "train accuracy: 0.980466666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s - loss: 0.0648 - acc: 0.9804 - val_loss: 0.0566 - val_acc: 0.9833\n",
      "Test loss: 0.0621027650893\n",
      "Test accuracy: 0.9794\n",
      "train loss: 0.0565721624558\n",
      "train accuracy: 0.983266666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0649 - acc: 0.9808 - val_loss: 0.0614 - val_acc: 0.9815\n",
      "Test loss: 0.0683178422447\n",
      "Test accuracy: 0.9774\n",
      "train loss: 0.0614049476605\n",
      "train accuracy: 0.981483333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0648 - acc: 0.9806 - val_loss: 0.0611 - val_acc: 0.9818\n",
      "Test loss: 0.0680790311435\n",
      "Test accuracy: 0.9772\n",
      "train loss: 0.0611064140357\n",
      "train accuracy: 0.981816666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a2660898>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0603 - acc: 0.9817 - val_loss: 0.0545 - val_acc: 0.9836\n",
      "Test loss: 0.0615824451615\n",
      "Test accuracy: 0.9793\n",
      "train loss: 0.0544839485744\n",
      "train accuracy: 0.983583333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0599 - acc: 0.9822 - val_loss: 0.0540 - val_acc: 0.9841\n",
      "Test loss: 0.0633053048379\n",
      "Test accuracy: 0.9786\n",
      "train loss: 0.0539665283826\n",
      "train accuracy: 0.984083333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0606 - acc: 0.9821 - val_loss: 0.0596 - val_acc: 0.9818\n",
      "Test loss: 0.0665394027823\n",
      "Test accuracy: 0.9791\n",
      "train loss: 0.0595670273825\n",
      "train accuracy: 0.98185\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0612 - acc: 0.9815 - val_loss: 0.0548 - val_acc: 0.9838\n",
      "Test loss: 0.0604550097536\n",
      "Test accuracy: 0.9798\n",
      "train loss: 0.0548122448564\n",
      "train accuracy: 0.983833333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff301e0bf28>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2ffd92080>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 25s - loss: 0.0568 - acc: 0.9830 - val_loss: 0.0537 - val_acc: 0.9835\n",
      "Test loss: 0.0641086292992\n",
      "Test accuracy: 0.9786\n",
      "train loss: 0.0537478041804\n",
      "train accuracy: 0.983483333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0571 - acc: 0.9827 - val_loss: 0.0497 - val_acc: 0.9850\n",
      "Test loss: 0.059316835722\n",
      "Test accuracy: 0.9801\n",
      "train loss: 0.0497197202645\n",
      "train accuracy: 0.984966666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0565 - acc: 0.9832 - val_loss: 0.0490 - val_acc: 0.9857\n",
      "Test loss: 0.0589282984793\n",
      "Test accuracy: 0.9801\n",
      "train loss: 0.04898808588\n",
      "train accuracy: 0.9857\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0565 - acc: 0.9831 - val_loss: 0.0510 - val_acc: 0.9856\n",
      "Test loss: 0.0594505204961\n",
      "Test accuracy: 0.9807\n",
      "train loss: 0.0510248247319\n",
      "train accuracy: 0.985633333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2ff9b46d8>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2ffd92080>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0542 - acc: 0.9835 - val_loss: 0.0475 - val_acc: 0.9859\n",
      "Test loss: 0.0582652159453\n",
      "Test accuracy: 0.9803\n",
      "train loss: 0.0474781228231\n",
      "train accuracy: 0.985866666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0543 - acc: 0.9838 - val_loss: 0.0495 - val_acc: 0.9851\n",
      "Test loss: 0.0609896766077\n",
      "Test accuracy: 0.9801\n",
      "train loss: 0.0495099388463\n",
      "train accuracy: 0.985083333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 28s - loss: 0.0544 - acc: 0.9836 - val_loss: 0.0487 - val_acc: 0.9856\n",
      "Test loss: 0.059666763697\n",
      "Test accuracy: 0.9804\n",
      "train loss: 0.0486758861919\n",
      "train accuracy: 0.985633333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 27s - loss: 0.0534 - acc: 0.9845 - val_loss: 0.0508 - val_acc: 0.9844\n",
      "Test loss: 0.0628660358671\n",
      "Test accuracy: 0.98\n",
      "train loss: 0.05081386939\n",
      "train accuracy: 0.98435\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2ffd92080>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2fd419710>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0508 - acc: 0.9850 - val_loss: 0.0443 - val_acc: 0.9870\n",
      "Test loss: 0.0554350465138\n",
      "Test accuracy: 0.9814\n",
      "train loss: 0.0442761995706\n",
      "train accuracy: 0.987033333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0511 - acc: 0.9847 - val_loss: 0.0464 - val_acc: 0.9859\n",
      "Test loss: 0.0592923553254\n",
      "Test accuracy: 0.9815\n",
      "train loss: 0.0463734948006\n",
      "train accuracy: 0.98585\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 26s - loss: 0.0504 - acc: 0.9849 - val_loss: 0.0457 - val_acc: 0.9865\n",
      "Test loss: 0.0580142358765\n",
      "Test accuracy: 0.9805\n",
      "train loss: 0.0457333791331\n",
      "train accuracy: 0.986533333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0507 - acc: 0.9847 - val_loss: 0.0439 - val_acc: 0.9873\n",
      "Test loss: 0.0555650731295\n",
      "Test accuracy: 0.9824\n",
      "train loss: 0.0439086938694\n",
      "train accuracy: 0.98735\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2ffd92080>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2fd0849b0>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0486 - acc: 0.9854 - val_loss: 0.0428 - val_acc: 0.9879\n",
      "Test loss: 0.055376595017\n",
      "Test accuracy: 0.9822\n",
      "train loss: 0.0428449258623\n",
      "train accuracy: 0.987933333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0485 - acc: 0.9853 - val_loss: 0.0421 - val_acc: 0.9880\n",
      "Test loss: 0.0549867644703\n",
      "Test accuracy: 0.9814\n",
      "train loss: 0.0420669083075\n",
      "train accuracy: 0.988\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0488 - acc: 0.9850 - val_loss: 0.0449 - val_acc: 0.9865\n",
      "Test loss: 0.0596335917396\n",
      "Test accuracy: 0.9797\n",
      "train loss: 0.0449289617841\n",
      "train accuracy: 0.986483333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 22s - loss: 0.0487 - acc: 0.9853 - val_loss: 0.0444 - val_acc: 0.9868\n",
      "Test loss: 0.0568681977017\n",
      "Test accuracy: 0.9811\n",
      "train loss: 0.0444417654422\n",
      "train accuracy: 0.98685\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2fd0849b0>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2fd0849b0>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0471 - acc: 0.9858 - val_loss: 0.0396 - val_acc: 0.9883\n",
      "Test loss: 0.0531600202007\n",
      "Test accuracy: 0.9816\n",
      "train loss: 0.0395715085907\n",
      "train accuracy: 0.988266666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0473 - acc: 0.9854 - val_loss: 0.0415 - val_acc: 0.9879\n",
      "Test loss: 0.0546230474499\n",
      "Test accuracy: 0.9806\n",
      "train loss: 0.041527570948\n",
      "train accuracy: 0.987933333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0464 - acc: 0.9860 - val_loss: 0.0406 - val_acc: 0.9883\n",
      "Test loss: 0.0553861612765\n",
      "Test accuracy: 0.9814\n",
      "train loss: 0.0405807837805\n",
      "train accuracy: 0.988333333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0465 - acc: 0.9859 - val_loss: 0.0426 - val_acc: 0.9879\n",
      "Test loss: 0.058110639938\n",
      "Test accuracy: 0.9805\n",
      "train loss: 0.0426184654473\n",
      "train accuracy: 0.987883333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2a0c9d9e8>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29f96f4e0>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0451 - acc: 0.9868 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "Test loss: 0.0586094034615\n",
      "Test accuracy: 0.9806\n",
      "train loss: 0.0408330308356\n",
      "train accuracy: 0.988266666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 22s - loss: 0.0442 - acc: 0.9866 - val_loss: 0.0380 - val_acc: 0.9892\n",
      "Test loss: 0.05268645214\n",
      "Test accuracy: 0.9821\n",
      "train loss: 0.038015707725\n",
      "train accuracy: 0.989216666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0443 - acc: 0.9871 - val_loss: 0.0388 - val_acc: 0.9888\n",
      "Test loss: 0.0539466742922\n",
      "Test accuracy: 0.9821\n",
      "train loss: 0.0387966256613\n",
      "train accuracy: 0.988833333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0450 - acc: 0.9863 - val_loss: 0.0387 - val_acc: 0.9891\n",
      "Test loss: 0.0531383833352\n",
      "Test accuracy: 0.9828\n",
      "train loss: 0.0386857620037\n",
      "train accuracy: 0.989116666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29f5a9c50>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29f5a9c50>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0424 - acc: 0.9876 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "Test loss: 0.0560503554706\n",
      "Test accuracy: 0.9811\n",
      "train loss: 0.0392932522271\n",
      "train accuracy: 0.98875\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0437 - acc: 0.9868 - val_loss: 0.0376 - val_acc: 0.9893\n",
      "Test loss: 0.054072846912\n",
      "Test accuracy: 0.982\n",
      "train loss: 0.0375606348331\n",
      "train accuracy: 0.989266666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0422 - acc: 0.9877 - val_loss: 0.0370 - val_acc: 0.9896\n",
      "Test loss: 0.0546892471446\n",
      "Test accuracy: 0.9827\n",
      "train loss: 0.0369980864897\n",
      "train accuracy: 0.9896\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0438 - acc: 0.9867 - val_loss: 0.0399 - val_acc: 0.9884\n",
      "Test loss: 0.0543372708636\n",
      "Test accuracy: 0.9821\n",
      "train loss: 0.0399070196583\n",
      "train accuracy: 0.988383333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29f5a9c50>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29d02fd30>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0412 - acc: 0.9877 - val_loss: 0.0378 - val_acc: 0.9887\n",
      "Test loss: 0.0542787751972\n",
      "Test accuracy: 0.9824\n",
      "train loss: 0.0377653616814\n",
      "train accuracy: 0.988666666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0409 - acc: 0.9881 - val_loss: 0.0350 - val_acc: 0.9899\n",
      "Test loss: 0.0529891653464\n",
      "Test accuracy: 0.9822\n",
      "train loss: 0.0349801837437\n",
      "train accuracy: 0.98995\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0411 - acc: 0.9874 - val_loss: 0.0379 - val_acc: 0.9884\n",
      "Test loss: 0.0548976807016\n",
      "Test accuracy: 0.9813\n",
      "train loss: 0.0378633176319\n",
      "train accuracy: 0.98845\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 22s - loss: 0.0411 - acc: 0.9876 - val_loss: 0.0353 - val_acc: 0.9900\n",
      "Test loss: 0.0504936912043\n",
      "Test accuracy: 0.9822\n",
      "train loss: 0.0353397157454\n",
      "train accuracy: 0.990033333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29f5a9c50>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29cca7240>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0396 - acc: 0.9882 - val_loss: 0.0371 - val_acc: 0.9893\n",
      "Test loss: 0.0550005088641\n",
      "Test accuracy: 0.9837\n",
      "train loss: 0.0371043439182\n",
      "train accuracy: 0.989316666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0404 - acc: 0.9877 - val_loss: 0.0370 - val_acc: 0.9890\n",
      "Test loss: 0.0547068155409\n",
      "Test accuracy: 0.983\n",
      "train loss: 0.0370009588342\n",
      "train accuracy: 0.988983333333\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s - loss: 0.0397 - acc: 0.9881 - val_loss: 0.0346 - val_acc: 0.9899\n",
      "Test loss: 0.0534507334841\n",
      "Test accuracy: 0.9821\n",
      "train loss: 0.0345990553263\n",
      "train accuracy: 0.9899\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0396 - acc: 0.9882 - val_loss: 0.0359 - val_acc: 0.9896\n",
      "Test loss: 0.0538265216447\n",
      "Test accuracy: 0.9823\n",
      "train loss: 0.0358858498211\n",
      "train accuracy: 0.9896\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff2992618d0>\n",
      "_cloneModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29bb5aeb8>\n",
      "_cloneModel\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s - loss: 0.0382 - acc: 0.9885 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Test loss: 0.0510953555471\n",
      "Test accuracy: 0.9822\n",
      "train loss: 0.0325197746227\n",
      "train accuracy: 0.9907\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004, 0.99070000000000003]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0386 - acc: 0.9885 - val_loss: 0.0329 - val_acc: 0.9907\n",
      "Test loss: 0.051713259716\n",
      "Test accuracy: 0.9825\n",
      "train loss: 0.0328707597339\n",
      "train accuracy: 0.990716666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004, 0.99070000000000003, 0.99071666666666669]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 23s - loss: 0.0380 - acc: 0.9887 - val_loss: 0.0341 - val_acc: 0.9899\n",
      "Test loss: 0.0532735308366\n",
      "Test accuracy: 0.9829\n",
      "train loss: 0.0340908791273\n",
      "train accuracy: 0.989916666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004, 0.99070000000000003, 0.99071666666666669, 0.98991666666666667]\n",
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 22s - loss: 0.0381 - acc: 0.9888 - val_loss: 0.0322 - val_acc: 0.9909\n",
      "Test loss: 0.0512152155862\n",
      "Test accuracy: 0.9827\n",
      "train loss: 0.0321774686449\n",
      "train accuracy: 0.990916666667\n",
      "~\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004, 0.99070000000000003, 0.99071666666666669, 0.98991666666666667, 0.99091666666666667]\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29bb5aeb8>\n",
      "_cloneModel\n",
      "repopulate\n",
      "tmp\n",
      "<keras.engine.training.Model object at 0x7ff29bb5aeb8>\n",
      "_cloneModel\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import numpy\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "accList = []\n",
    "    \n",
    "class population:\n",
    "    def __init__(self, population = 4):\n",
    "        self.population = population\n",
    "        self.modelList = []\n",
    "        self.massacreRate = 0.4\n",
    "        self.accList = []\n",
    "        for i in range(self.population):\n",
    "            self.modelList.append(self._createModel())\n",
    "    def _createModel(self):\n",
    "        digit_input = Input(shape=(28, 28, 1))\n",
    "\n",
    "        x = Conv2D(5, kernel_size=(3, 3),\n",
    "                         activation='relu',\n",
    "                         input_shape=input_shape)(digit_input)\n",
    "\n",
    "        x = Conv2D(5, (3, 3), activation='relu')(x)\n",
    "\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        #x = Dropout(0.25)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(30, activation='relu')(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        out = Dense(num_classes, activation='softmax')(x)\n",
    "        model = Model(digit_input, outputs=out)\n",
    "        print('model defined')\n",
    "        return model\n",
    "    def _getRandomModel(self):\n",
    "        tmp = random.choice(self.modelList)\n",
    "        while(not tmp):\n",
    "            tmp = random.choice(self.modelList)\n",
    "        print(\"tmp\")\n",
    "        print(tmp)\n",
    "        return tmp\n",
    "    def _cloneModel(self, model_from, model_to):\n",
    "        print(\"_cloneModel\")\n",
    "        model_from.save('temp.h5')\n",
    "        model_to = load_model('temp.h5')\n",
    "        return model_to\n",
    "    def _trainModel(self, model):\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=1,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_train, y_train))#validate by training data\n",
    "        model.score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', model.score[0])\n",
    "        print('Test accuracy:', model.score[1])\n",
    "        model.score = model.evaluate(x_train, y_train, verbose=0)\n",
    "        print('train loss:', model.score[0])\n",
    "        print('train accuracy:', model.score[1])\n",
    "        print('~')\n",
    "        self.accList.append(model.score[1])\n",
    "        print(self.accList)\n",
    "    def iniOneModelWith(self, _str):\n",
    "        self.modelList[0] = load_model(_str)\n",
    "    def saveOneModeWith(self, _str):\n",
    "        self.modelList[0].save(_str)\n",
    "    def printAllScore(self):\n",
    "        for elem in self.modelList:\n",
    "            print(elem.score[1])\n",
    "    def trainAll(self, epoch=1):\n",
    "        for i in range(epoch):\n",
    "            for model in self.modelList:\n",
    "                self._trainModel(model)\n",
    "    def sortAll(self):\n",
    "        self.modelList.sort(key = lambda elem:elem.score[1],\n",
    "            reverse=True)\n",
    "    def massacre(self):\n",
    "        for index, elem in enumerate(self.modelList):\n",
    "            if index>len(self.modelList)*self.massacreRate:\n",
    "                self.modelList[index] = None\n",
    "    def repopulate(self):\n",
    "        for index, elem in enumerate(self.modelList):\n",
    "            if elem == None:\n",
    "                print('repopulate')\n",
    "                self.modelList[index] = self._cloneModel(self._getRandomModel(), elem)\n",
    "                self.modelList[index].score = self.modelList[index].evaluate(x_train, y_train, verbose=0)\n",
    "    def runLifeCycle(self, times):\n",
    "        for _ in range(times):\n",
    "            self.trainAll()\n",
    "            self.sortAll()\n",
    "            self.massacre()\n",
    "            self.repopulate()\n",
    "    def scoreAllWithTest(self):\n",
    "        # for all!!!! not finished\n",
    "        model.score = model.evaluate(x_test, y_test, verbose=0)\n",
    "                \n",
    "p1 = population(1)\n",
    "\n",
    "p2 = population()\n",
    "'''\n",
    "p1.iniOneModelWith('champ.h5')\n",
    "p1.repopulate()\n",
    "\n",
    "'''\n",
    "\n",
    "p1.runLifeCycle(20)\n",
    "p2.runLifeCycle(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91659999999999997, 0.93731666666666669, 0.94846666666666668, 0.95679999999999998, 0.96401666666666663, 0.96660000000000001, 0.97298333333333331, 0.97583333333333333, 0.9751333333333333, 0.97924999999999995, 0.97971666666666668, 0.9821833333333333, 0.98324999999999996, 0.98440000000000005, 0.98416666666666663, 0.98536666666666661, 0.98680000000000001, 0.98760000000000003, 0.98798333333333332, 0.98848333333333338]\n",
      "[0.92546666666666666, 0.93741666666666668, 0.93311666666666671, 0.93889999999999996, 0.95658333333333334, 0.95630000000000004, 0.95763333333333334, 0.95783333333333331, 0.96643333333333337, 0.96791666666666665, 0.96618333333333328, 0.96688333333333332, 0.97086666666666666, 0.97209999999999996, 0.97101666666666664, 0.97376666666666667, 0.9761333333333333, 0.97629999999999995, 0.97506666666666664, 0.97409999999999997, 0.97841666666666671, 0.9785166666666667, 0.97850000000000004, 0.97828333333333328, 0.97950000000000004, 0.97946666666666671, 0.9791333333333333, 0.97931666666666661, 0.98140000000000005, 0.98041666666666671, 0.98041666666666671, 0.98216666666666663, 0.98046666666666671, 0.98326666666666662, 0.98148333333333337, 0.98181666666666667, 0.98358333333333337, 0.98408333333333331, 0.98185, 0.98383333333333334, 0.98348333333333338, 0.98496666666666666, 0.98570000000000002, 0.98563333333333336, 0.98586666666666667, 0.98508333333333331, 0.98563333333333336, 0.98434999999999995, 0.98703333333333332, 0.98585, 0.98653333333333337, 0.98734999999999995, 0.98793333333333333, 0.98799999999999999, 0.98648333333333338, 0.98685, 0.98826666666666663, 0.98793333333333333, 0.98833333333333329, 0.98788333333333334, 0.98826666666666663, 0.98921666666666663, 0.98883333333333334, 0.98911666666666664, 0.98875000000000002, 0.98926666666666663, 0.98960000000000004, 0.98838333333333328, 0.98866666666666669, 0.98995, 0.98845000000000005, 0.99003333333333332, 0.98931666666666662, 0.98898333333333333, 0.9899, 0.98960000000000004, 0.99070000000000003, 0.99071666666666669, 0.98991666666666667, 0.99091666666666667]\n",
      "[0.92546666666666666, 0.95658333333333334, 0.96643333333333337, 0.97086666666666666, 0.9761333333333333, 0.97841666666666671, 0.97950000000000004, 0.98140000000000005, 0.98046666666666671, 0.98358333333333337, 0.98348333333333338, 0.98586666666666667, 0.98703333333333332, 0.98793333333333333, 0.98826666666666663, 0.98826666666666663, 0.98875000000000002, 0.98866666666666669, 0.98931666666666662, 0.99070000000000003]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMJb4jTEmwljiN8aYCPP/AdZNT7QSX+4kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2b68aca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "print(p1.accList)\n",
    "print(p2.accList)\n",
    "outF = [p2.accList[i] for i in range(len(p2.accList)) if i%4 == 0]\n",
    "print(outF)\n",
    "plt.plot(p1.accList)\n",
    "plt.plot(outF)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#p1.runLifeCycle(10)\n",
    "'''\n",
    "p1.saveOneModeWith('champ.h5')\n",
    "\n",
    "model.save('my_model'+str(model_index)+'.h5')\n",
    "model = load_model('my_model'+str(model_index)+'.h5')\n",
    "\n",
    "p1.iniOneModelWith('champ.h5')\n",
    "p1.repopulate()\n",
    "p1.trainAll()\n",
    "p1.printAllScore()\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
